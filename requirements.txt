# =============================================================================
# Core Framework
# =============================================================================
fastapi>=0.115.0
uvicorn[standard]>=0.30.0
gradio>=5.0.0

# =============================================================================
# LLM Inference
# =============================================================================
# llama-cpp-python is installed separately with platform-specific flags:
#   Mac:   CMAKE_ARGS="-DGGML_METAL=on" pip install llama-cpp-python
#   Linux: pip install llama-cpp-python
#   CUDA:  CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python

# =============================================================================
# LangChain
# =============================================================================
langchain>=0.3.0
langchain-community>=0.3.0
langchain-core>=0.3.0
langchain-text-splitters>=0.3.0

# =============================================================================
# Vector Store & Embeddings
# =============================================================================
faiss-cpu>=1.7.0
sentence-transformers>=2.2.0

# =============================================================================
# Document Loaders
# =============================================================================
pypdf>=4.0.0
docx2txt>=0.8
unstructured>=0.10.0
tabulate>=0.9.0

# =============================================================================
# Model Download
# =============================================================================
huggingface-hub>=0.20.0

# =============================================================================
# Utilities
# =============================================================================
pydantic>=2.0.0
python-multipart>=0.0.9